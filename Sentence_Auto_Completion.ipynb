{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing the required libraries"
      ],
      "metadata": {
        "id": "ATS_yCdprEPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJmURmFoq22H"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from urllib import request\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function finds the occurence of the give input in the corpus (First the last three words, if that's not present then the last two words and then finally the last word alone)"
      ],
      "metadata": {
        "id": "-MH-URX3_6VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check(inpu,words):\n",
        "\n",
        "    three=[]\n",
        "    two=[]\n",
        "    one=[]\n",
        "\n",
        "    if len(inpu)>=3:\n",
        "        for i in range(len(words)-3):\n",
        "            if words[i]==inpu[len(inpu)-3] and words[i+1]==inpu[len(inpu)-2] and words[i+2]==inpu[len(inpu)-1]:\n",
        "               three.append(i+3)\n",
        "        if len(three) !=0:\n",
        "            return three\n",
        "\n",
        "    if (len(three)==0 or len(inpu)<3) and len(inpu)>1:\n",
        "        for i in range(len(words)-2):\n",
        "            if words[i]==inpu[len(inpu)-2] and words[i+1]==inpu[len(inpu)-1]:\n",
        "                two.append(i+2)\n",
        "        if len(two) !=0:\n",
        "            return two\n",
        "\n",
        "    if len(three)==0 and len(two)==0:\n",
        "        for i in range(len(words)-1):\n",
        "            if words[i]==inpu[len(inpu)-1]:\n",
        "                one.append(i+1)\n",
        "        return one"
      ],
      "metadata": {
        "id": "UFn2S6ZO_5es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function finds out which word appears most after the given occurences and outputs that (and it's next word) along with its probability."
      ],
      "metadata": {
        "id": "TPJn5PWzAORt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_prob(inpu,words):\n",
        "    arr_ = check(inpu,words)\n",
        "    if len(arr_)==0:     #returns nothing if the word in input is not present in the corpus (EX. Laptop)\n",
        "      return '','Undefined'\n",
        "    arr=[]\n",
        "    for x in arr_:\n",
        "        arr.append(words[x])\n",
        "    a = Counter(arr)\n",
        "    prob = round(a[max(a,key= lambda x:a[x])]/sum(a.values()),3)\n",
        "    X = arr.index(max(a,key= lambda x:a[x]))\n",
        "    ans = max(a,key= lambda x:a[x]) + \" \" + words[arr_[X]+1] \n",
        "    return ans,prob"
      ],
      "metadata": {
        "id": "QzZyfFe9AYCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downlaoding the Corpus and tokenizing it.\n",
        "12 books are considered for the corpus:\n",
        "1. Crime and Punishment by Fyodor Dostoevsky\n",
        "2. Moby Dick by Herman Melville\n",
        "3. Adventures of Sherlcok Holmes by Arthur Conan Doyle\n",
        "4. Treasure Island by RL Stevenson\n",
        "5. Adventures of Huckleberry Finn by Mark Twain\n",
        "6. Dracula by Bram Stoker\n",
        "7. A Tale of Two Cities by Charles Dickens\n",
        "8. Little Women by Louisa May Alcott\n",
        "9. Twenty Years After by Alexandre Dumas\n",
        "10. The Works of Edgar Allan Poe by Edgar Allan Poe\n",
        "11. Peter Pan by James M. Barrie\n",
        "12. Oliver Twist by Charles Dickens\n",
        "\n"
      ],
      "metadata": {
        "id": "YsNnptvjrVdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = [\"http://www.gutenberg.org/files/2554/2554-0.txt\",\"https://www.gutenberg.org/files/2489/2489-0.txt\",\"https://www.gutenberg.org/files/48320/48320-0.txt\",\"https://www.gutenberg.org/files/120/120-0.txt\",\"https://www.gutenberg.org/files/76/76-0.txt\",\"https://www.gutenberg.org/files/345/345-0.txt\",\"https://www.gutenberg.org/files/98/98-0.txt\",\"https://www.gutenberg.org/files/514/514-0.txt\",\"https://www.gutenberg.org/files/1259/1259-0.txt\",\"https://www.gutenberg.org/files/2148/2148-0.txt\",\"https://www.gutenberg.org/files/16/16-0.txt\",\"https://www.gutenberg.org/files/730/730-0.txt\"]\n",
        "words_=[]\n",
        "for i in range(len(url)):\n",
        "    response = request.urlopen(url[i])\n",
        "    raw = response.read().decode('utf-8-sig')\n",
        "    temp_words = word_tokenize(raw)\n",
        "    words_.extend(temp_words)\n",
        "    temp_words = []\n"
      ],
      "metadata": {
        "id": "4q0qty9vq76R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the corpus into a Convenient format (all lower, no special characters)"
      ],
      "metadata": {
        "id": "TqqjWq9CUleE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "\n",
        "for x in words_:\n",
        "    if x[-1] == '.':\n",
        "      x = x.rstrip('.')\n",
        "    if x.isalpha():\n",
        "      words.append(x.lower())\n",
        "#print(len(words)) - 1,763,402 words are considered"
      ],
      "metadata": {
        "id": "ZeMfOkyjUyOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Handling  "
      ],
      "metadata": {
        "id": "OfdaFIcqttV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str_ = []\n",
        "filename = \"AutoComplete.txt\"\n",
        "with open(filename) as f:\n",
        "    for line in f:\n",
        "      str_.append(line.rstrip())\n"
      ],
      "metadata": {
        "id": "bJJfdTf4tv1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output"
      ],
      "metadata": {
        "id": "5y-dJkwcIoUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(str_)):\n",
        "    inpu=[]\n",
        "    for x in str_[i].split():\n",
        "        if x.isalpha():\n",
        "            inpu.append(x.lower())\n",
        "    print(str_ [i]+ \" \"+ max_prob(inpu,words)[0])\n",
        "    print(\"Suggestion has a probability:\",max_prob(inpu,words)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYdR2UFeIqLP",
        "outputId": "9ca58fb3-125f-4edb-e8b0-4d0e41b9adbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Practice makes a man who\n",
            "Suggestion has a probability: 0.133\n",
            "2. Like share and when you\n",
            "Suggestion has a probability: 0.167\n",
            "3. The list has been forced\n",
            "Suggestion has a probability: 0.161\n",
            "4. She trekked towards the outer\n",
            "Suggestion has a probability: 0.521\n",
            "5. Honesty is the best policy\n",
            "Suggestion has a probability: 1.0\n",
            "6. I am short and was\n",
            "Suggestion has a probability: 0.098\n",
            "7. Thinking of Sanskrit she also\n",
            "Suggestion has a probability: 1.0\n",
            "8. This is a very civilized\n",
            "Suggestion has a probability: 0.092\n",
            "9. Plants have a good memory\n",
            "Suggestion has a probability: 0.052\n",
            "10. No is a mere word\n",
            "Suggestion has a probability: 1.0\n",
            "11. Happy neurons generated in him\n",
            "Suggestion has a probability: 0.333\n",
            "12. No more excuses to prevaricate\n",
            "Suggestion has a probability: 0.286\n",
            "13. Coming all the time but\n",
            "Suggestion has a probability: 1.0\n",
            "14. Library with five hundred thousand\n",
            "Suggestion has a probability: 0.333\n",
            "15. And then there was a\n",
            "Suggestion has a probability: 0.286\n",
            "16. A sketcher in the united\n",
            "Suggestion has a probability: 0.269\n",
            "17. A body in it rings\n",
            "Suggestion has a probability: 1.0\n",
            "18. That's the reason why most\n",
            "Suggestion has a probability: 0.25\n",
            "19. My birthday is the same\n",
            "Suggestion has a probability: 1.0\n",
            "20. I like this room most\n",
            "Suggestion has a probability: 1.0\n",
            "21. What a lovely day again\n",
            "Suggestion has a probability: 1.0\n",
            "22. I would rather die under\n",
            "Suggestion has a probability: 0.214\n",
            "23. I want to see your\n",
            "Suggestion has a probability: 0.088\n",
            "24. Do you like to comb\n",
            "Suggestion has a probability: 0.2\n",
            "25. Put the toys in this\n",
            "Suggestion has a probability: 0.333\n",
            "26. Let us go and try\n",
            "Suggestion has a probability: 0.15\n",
            "27. She found a little paper\n",
            "Suggestion has a probability: 1.0\n",
            "28. The ball is over cough\n",
            "Suggestion has a probability: 1.0\n",
            "29. I have three who have\n",
            "Suggestion has a probability: 0.5\n",
            "30. Please pass the night on\n",
            "Suggestion has a probability: 0.184\n",
            "31. The birds flew to katerina\n",
            "Suggestion has a probability: 0.102\n",
            "32. The dog ran to the\n",
            "Suggestion has a probability: 0.139\n",
            "33. She sang a serenade in\n",
            "Suggestion has a probability: 1.0\n",
            "34. The girl went to bed\n",
            "Suggestion has a probability: 0.5\n",
            "35. She ate french and dancing\n",
            "Suggestion has a probability: 0.053\n",
            "36. Please close the door the\n",
            "Suggestion has a probability: 0.286\n",
            "37. Winter season is a plaything\n",
            "Suggestion has a probability: 0.086\n",
            "38. My new laptop \n",
            "Suggestion has a probability: Undefined\n",
            "39. I like playing then on\n",
            "Suggestion has a probability: 1.0\n",
            "40. Do you know that he\n",
            "Suggestion has a probability: 0.138\n",
            "41. I want a fortune he\n",
            "Suggestion has a probability: 0.143\n",
            "42. The sun is high over\n",
            "Suggestion has a probability: 0.222\n",
            "43. Do you like to comb\n",
            "Suggestion has a probability: 0.2\n",
            "44. Please wash your hands and\n",
            "Suggestion has a probability: 1.0\n",
            "45. I study in scarlet i\n",
            "Suggestion has a probability: 0.429\n",
            "46. He is my friend and\n",
            "Suggestion has a probability: 0.25\n",
            "47. I am so glad that\n",
            "Suggestion has a probability: 0.18\n",
            "48. Her dog likes to be\n",
            "Suggestion has a probability: 0.148\n",
            "49. My teacher is a plaything\n",
            "Suggestion has a probability: 0.086\n",
            "50. The book is one of\n",
            "Suggestion has a probability: 0.5\n"
          ]
        }
      ]
    }
  ]
}